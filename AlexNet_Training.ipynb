{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet_Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D40wXhjiP0P7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as utils\n",
        "\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsxIxbvjP4uP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchsize = 400\n",
        "learningrate = 0.005\n",
        "epochs = 500 \n",
        "print_freq = 10"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLTqwvq2P6ij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f241cc3-cdd0-4488-a68d-33a4a92f9c74"
      },
      "source": [
        "transform = transforms.Compose(\n",
        " [transforms.ToTensor(),\n",
        " transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "tensor_x = torch.from_numpy(np.load('./drive/My Drive/Colab Notebooks/X_train.npy'))\n",
        "tensor_y = torch.from_numpy(np.load('./drive/My Drive/Colab Notebooks/Y_train.npy'))\n",
        "tensor_x = torch.reshape(tensor_x, (tensor_x.size(0), tensor_x.size(1), tensor_x.size(2), 1))\n",
        "print(tensor_x.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 500, 500, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-FCavBBQAQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a82b277-28d2-4f18-f56b-c61925492dfc"
      },
      "source": [
        "trainset = utils.TensorDataset(tensor_x,tensor_y) \n",
        "trainloader = utils.DataLoader(trainset,  batch_size=batchsize)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXg3vB2jQGf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a6d8f0f0-1060-463b-d0fe-fd10e6e1104c"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(images.size())\n",
        "images = images.permute(0, 3, 1, 2)\n",
        "print(images.size())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([400, 500, 500, 1])\n",
            "torch.Size([400, 1, 500, 500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYONsm1lQI8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def poisson_noise(X_torch):\n",
        "    X = X_torch.cpu().numpy()\n",
        "    vals = len(np.unique(X))\n",
        "    vals = 2 ** np.ceil(np.log2(vals))\n",
        "    noisy = np.random.poisson(X * vals) / float(vals)\n",
        "    return noisy\n",
        "\n",
        "def speckle_noise(X_torch):\n",
        "    X = X_torch.cpu().numpy()\n",
        "    X = X.reshape((X.shape[0], X.shape[1])) \n",
        "    row,col = X.shape\n",
        "    s_vs_p = 0.5\n",
        "    amount = 0.02\n",
        "    out = np.copy(X)\n",
        "    num_salt = np.ceil(amount * X.size * s_vs_p)\n",
        "    coords = [np.random.randint(0, i - 1, int(num_salt))\n",
        "              for i in X.shape]\n",
        "    out[coords] = 1\n",
        "    num_pepper = np.ceil(amount* X.size * (1. - s_vs_p))\n",
        "    coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
        "              for i in X.shape]\n",
        "    out[coords] = 0\n",
        "    return out.reshape((out.shape[0], out.shape[1],1))\n",
        "\n",
        "def flip_2D(X_torch):\n",
        "    return np.fliplr(X_torch.cpu().numpy())\n",
        "\n",
        "def augment_batch(inputs, labels):\n",
        "    x = np.zeros((inputs.size()[0] * 2 ,inputs.size()[1],inputs.size()[2], inputs.size()[3]))\n",
        "    y = np.zeros((labels.size()[0] * 2))\n",
        "    for i in range(len(inputs)):\n",
        "        x[2*i] = inputs[i].cpu().numpy()\n",
        "        y[2*i] = labels[i].cpu().numpy()\n",
        "        if (i%3 == 2):\n",
        "          x[2*i+1] = flip_2D(inputs[i])\n",
        "          y[2*i+1] = labels[i]\n",
        "        elif (i%3 == 0):\n",
        "            x[2*i+1] = poisson_noise(inputs[i])\n",
        "            y[2*i+1] = labels[i]\n",
        "        else:\n",
        "            x[2*i+1] = speckle_noise(inputs[i])\n",
        "            y[2*i+1] = labels[i]\n",
        "    return torch.from_numpy(x), torch.from_numpy(y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_k7qwf-QS3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "2e4e0b85-a1f0-4a74-e54e-d3b0c081a4c7"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(Net, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 50, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(50, 100, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(100, 75, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(75, 30, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1080, 540),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(540, 540),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(540, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x.float())\n",
        "        x = self.avgpool(x.float())\n",
        "        x = x.view(x.size(0), 1080)\n",
        "        x = self.classifier(x.float())\n",
        "        return x\n",
        "    \n",
        "net = Net()\n",
        "net.to(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 50, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(50, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(100, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(75, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=1080, out_features=540, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=540, out_features=540, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=540, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIEMUZRgRGZk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c21a9e42-9890-4b4f-a303-58be1aa7d2e5"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.AdamW(net.parameters(), lr=learningrate)\n",
        "avg_losses = []\n",
        "for epoch in range(epochs): \n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        \n",
        "        #inputs, labels = augment_batch(inputs, labels)\n",
        "        \n",
        "        inputs = inputs.permute(0, 3, 1, 2)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_func(outputs, labels.long())\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        opt.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        if i % print_freq == print_freq - 1:\n",
        "            avg_loss = running_loss / print_freq\n",
        "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(epoch, i, avg_loss))\n",
        "            avg_losses.append(avg_loss)\n",
        "            running_loss = 0.0\n",
        "print('Finished Training.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch: 0, i:    19] avg mini-batch loss: 292.512\n",
            "[epoch: 1, i:    19] avg mini-batch loss: 0.649\n",
            "[epoch: 2, i:    19] avg mini-batch loss: 0.589\n",
            "[epoch: 3, i:    19] avg mini-batch loss: 0.580\n",
            "[epoch: 4, i:    19] avg mini-batch loss: 0.581\n",
            "[epoch: 5, i:    19] avg mini-batch loss: 0.580\n",
            "[epoch: 6, i:    19] avg mini-batch loss: 0.580\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agR1Z3nhRIsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}